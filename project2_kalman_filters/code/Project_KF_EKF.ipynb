{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping and Perception for an autonomous robot (0510-7951)\n",
    "\n",
    "### 2024/B\n",
    "\n",
    "### Written by Roy Orfaig\n",
    "\n",
    "Exercise 2:\n",
    "---\n",
    "**Part A** (50 points)\n",
    "\n",
    "Localization based on Kalman Filter\n",
    "\n",
    "**Part B** (50 points)\n",
    "\n",
    "Localization based on Extended Kalman Filter\n",
    "\n",
    "\n",
    "-------------------------------------\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Go to [**KITTI dataset**](http://www.cvlibs.net/datasets/kitti/) ,and download your specific records (chose \"sync\" recording)\n",
    "2. Fill in the code the \"TODO\" section\n",
    "2. Answer the question inside the sections\n",
    "3. **Please copy all the results to the report:**\n",
    "  - Outputs- Images, tables, scores,etc\n",
    "  - Performace, analysis and your explanations.\n",
    "  - Attach the completed notebook to the report package.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nadav\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "project_path = r\"C:\\Users\\Nadav\\Desktop\\TAU\\מיפוי וחישה למערכות אוטונמיות\\Project_2\\Project_KF_EKF_python\"\n",
    "sys.path.append(project_path)\n",
    "\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.patches import Ellipse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import graphs\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from data_preparation import build_LLA_GPS_trajectory,build_GPS_trajectory,add_gaussian_noise,add_gaussian_noise_dict, normalize_angle,normalize_angles_array\n",
    "from utils.misc_tools import error_ellipse\n",
    "from utils.ellipse import draw_ellipse\n",
    "from utils.misc_tools import error_ellipse\n",
    "from utils.ellipse import draw_ellipse\n",
    "from utils.misc_tools import error_ellipse\n",
    "from data_loader import DataLoader\n",
    "from utils.plot_state import plot_state\n",
    "from data_preparation import normalize_angle, normalize_angles_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student name: Nadav Marciano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID: 305165698"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record id (kitti): 2011_09_30_drive_0020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change that:\n",
    "random.seed(1)\n",
    "np.random.seed(2)\n",
    "\n",
    "font = {'size': 20}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"/Users/Nadav/Desktop/TAU\"#\"TODO\" (insert the correct path)\n",
    "date = '2011_09_30'#\"TODO\" (insert  the correct folder)\n",
    "drive = '0020' #\"TODO\" - (insert your correct record number)\n",
    "pwd = os.getcwd()\n",
    "# dat_dir = os.path.join(pwd,\"data\") \n",
    "\n",
    "dataset = DataLoader(basedir, date, drive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graphs(folder=None, file_name=None):\n",
    "    \"\"\"\n",
    "    Saves or shows the current plot\n",
    "    Args:\n",
    "        folder: optional, must be provided with file_name too, the image will be saved to this path with the given file name\n",
    "        file_name: optional, must be provided with folder too, the image will be saved to this path with the given file name\n",
    "    \"\"\"\n",
    "    if not folder or not file_name:\n",
    "        plt.show()\n",
    "    else:\n",
    "        file_name = \"{}/{}.png\".format(folder, file_name)\n",
    "        figure = plt.gcf()  # get current figure\n",
    "        number_of_subplots_in_figure = len(plt.gcf().get_axes())\n",
    "        figure.set_size_inches(number_of_subplots_in_figure * 18, 18)\n",
    "        ram = io.BytesIO()\n",
    "        plt.savefig(ram, format='png', dpi=100)\n",
    "        ram.seek(0)\n",
    "        im = Image.open(ram)\n",
    "        im2 = im.convert('RGB').convert('P', palette=Image.ADAPTIVE)\n",
    "        im2.save(file_name, format='PNG')\n",
    "        plt.close(figure)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A\n",
    "## Localization based on Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the #TODO sections within the KalmanFilter class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter:\n",
    "    \"\"\"\n",
    "    class for the implementation of Kalman filter\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, enu_noise, times, vl, vf, sigma_xy, sigma_n, sigma_vx, sigma_vy, k, is_dead_reckoning=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            enu_noise: enu data with noise\n",
    "            times: elapsed time in seconds from the first timestamp in the sequence\n",
    "            sigma_xy: sigma in the x and y axis as provided in the question\n",
    "            sigma_vx: sigma in the x velocity\n",
    "            sigma_vy: sigma in the y velocity\n",
    "            sigma_n: hyperparameter used to fine tune the filter\n",
    "            is_dead_reckoning: should dead reckoning be applied after 5.0 seconds when applying the filter\n",
    "            k: The factor kk used to enlarge the initial covariance matrix (this is NOT the gain K_t)\n",
    "        \"\"\"\n",
    "        self.enu_noise = enu_noise\n",
    "        self.times = times\n",
    "        self.sigma_xy = sigma_xy\n",
    "        self.sigma_n = sigma_n\n",
    "        self.sigma_vx = sigma_vx\n",
    "        self.sigma_vy = sigma_vy\n",
    "        self.k = k\n",
    "        self.is_dead_reckoning = is_dead_reckoning\n",
    "        self.starting_time_dead_reck=5 #[seconds]\n",
    "\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the Kalman filter\n",
    "\n",
    "        outputs: enu_kf, covs\n",
    "        \"\"\"\n",
    "        # Note: set the type of conavinces as dtype='float32' , use numpy\n",
    "        B = np.zeros((4, 4),dtype='float32')\n",
    "        U = np.zeros((B.shape[0]),dtype='float32')\n",
    "        C = np.array([[1, 0, 0, 0],[0, 0, 1, 0]])\n",
    "\n",
    "        P0 = np.array([\n",
    "            [self.k * (self.sigma_xy ** 2), 0, 0, 0],\n",
    "            [0, self.k * (self.sigma_vy ** 2), 0, 0],\n",
    "            [0, 0, self.k * (self.sigma_xy ** 2), 0],\n",
    "            [0, 0, 0, self.k * (self.sigma_vy ** 2)]\n",
    "        ])\n",
    "\n",
    "        Q = np.array([[self.sigma_xy ** 2, 0], [0, self.sigma_xy ** 2]])\n",
    "\n",
    "        # Kalman Filter initialization  #TODO\n",
    "        \n",
    "        muo_tO = np.array([[self.enu_noise[0, 0]], [10], [self.enu_noise[0, 1]], [10]])\n",
    "        sigma_t_minus1 = P0\n",
    "            \n",
    "        # Run Kalman filter \n",
    "        locations_kf = []\n",
    "        sigma_kf = []\n",
    "            \n",
    "        for idx, (enu_point, curr_timestemp) in enumerate(zip(self.enu_noise,self.times)):\n",
    "            if idx == 0: # stage 0\n",
    "               ## Kalman Filter initialization (t=0)       \n",
    "                muo_t_minus1 = muo_tO.flatten()\n",
    "                start_timestemp = curr_timestemp\n",
    "                prev_timestemp = curr_timestemp\n",
    "                locations_kf.append(muo_t_minus1[0::2]) #extract x and y from the state vector\n",
    "                sigma_kf.append(sigma_t_minus1)\n",
    "                continue\n",
    "\n",
    "            # Extract Noisy Measurement(x,y)\n",
    "            z_t = np.array([[self.enu_noise[idx, 0]], [self.enu_noise[idx, 1]]])\n",
    "            delta_t = (curr_timestemp - prev_timestemp).total_seconds()\n",
    "            time_since_start = (curr_timestemp - start_timestemp).total_seconds()\n",
    "            \n",
    "            A = np.array([[1, delta_t, 0, 0], [0, 1, 0, 0], [0, 0, 1, delta_t], [0, 0, 0, 1]])\n",
    "    \n",
    "            R = np.array([[0, 0, 0, 0], [0, delta_t, 0, 0], [0, 0, 0, 0], [0, 0, 0, delta_t]]) * (self.sigma_n ** 2)\n",
    "         \n",
    "            # Kalman Filter mechanizm: Hint: Use matrix multiplication (@ operator)\n",
    "            \n",
    "            muo_t_bar = A @ muo_t_minus1.reshape(-1, 1) + B @ U.reshape(-1, 1)\n",
    "            sigma_t_bar = A @ sigma_t_minus1 @ A.T + R\n",
    "            \n",
    "            K_t = sigma_t_bar @ C.T @ np.linalg.inv(C @ sigma_t_bar @ C.T + Q) \n",
    "            \n",
    "            if time_since_start >= self.starting_time_dead_reck and self.is_dead_reckoning:\n",
    "                 K_t = np.zeros_like(K_t)\n",
    "            muo_t = (muo_t_bar + K_t @ (z_t - (C @ muo_t_bar))).flatten()  \n",
    "            sigma_t = (np.eye(4) - K_t @ C) @ sigma_t_bar \n",
    "\n",
    "            muo_t_minus1 = muo_t\n",
    "            prev_timestemp = curr_timestemp\n",
    "            sigma_t_minus1 = sigma_t\n",
    "            locations_kf.append(muo_t[0::2]) # Extract x and y from the state vector as a vector\n",
    "            sigma_kf.append(sigma_t)\n",
    "\n",
    "        return np.array(locations_kf),np.array(sigma_kf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the #TODO sections within the ProjectQuestions1 class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectQuestions1:\n",
    "    def __init__(self, dataset, display_results, animation_results):\n",
    "        \"\"\"\n",
    "        Given a Loaded Kitti data set with the following ground truth values: tti dataset and adds noise to GT-gps values\n",
    "        - lat: latitude [deg]\n",
    "        - lon: longitude [deg]\n",
    "        - yaw: heading [rad]\n",
    "        - vf: forward velocity parallel to earth-surface [m/s]\n",
    "        - wz: angular rate around z axis [rad/s]\n",
    "        Builds the following np arrays:\n",
    "        - enu - lla converted to enu data\n",
    "        - times - for each frame, how much time has elapsed from the previous frame\n",
    "        - yaw_vf_wz - yaw, forward velocity and angular change rate\n",
    "        - enu_noise - enu with Gaussian noise (sigma_xy=3 meters)\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.display_results = display_results\n",
    "        self.animation_results = animation_results\n",
    "        self.enu, self.times, self.yaw_vf_vl_wz = build_GPS_trajectory(dataset)\n",
    "        self.location_GT = self.enu[:,0:2]\n",
    "\n",
    "        # add noise to the trajectory\n",
    "        self.sigma_xy = 3  # Set value for sigma_xy\n",
    "        self.sigma_vx = 1.3  # Set value for sigma_vx\n",
    "        self.sigma_vy = 1.3  # Set value for sigma_vy\n",
    "        self.sigma_n = 1.5  # Set value for sigma_n\n",
    "        self.k = 1  # Set value for k\n",
    "\n",
    "        e_noised = add_gaussian_noise(self.enu[:, 0], self.sigma_xy)\n",
    "        n_noised = add_gaussian_noise(self.enu[:, 1], self.sigma_xy)\n",
    "        u_noised = add_gaussian_noise(self.enu[:, 2], self.sigma_xy)\n",
    "        self.enu_noise = np.stack([e_noised, n_noised, u_noised], axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "        self.fig_dir_path = os.getcwd() + \"/Results_Q1/\"\n",
    "        if not os.path.exists(self.fig_dir_path):\n",
    "            os.makedirs(self.fig_dir_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_RMSE_maxE(X_Y_GT, X_Y_est, starting_point=100):\n",
    "        \"\"\"\n",
    "        This function calculates RMSE and maxE\n",
    "\n",
    "        Args:\n",
    "            X_Y_GT (np.ndarray): ground truth values of x and y\n",
    "            X_Y_est (np.ndarray): estimated values of x and y\n",
    "            starting_point (int): Starting point index for calculations\n",
    "\n",
    "        Returns:\n",
    "            (float, float): RMSE, maxE\n",
    "        \"\"\"\n",
    "        maxE = -1  # Initialize max error variable\n",
    "        num_of_elements = 0  # Initialize count of elements\n",
    "        e_squared_list = []  # List to store squared errors\n",
    "        err_x_arr = []  # List to store errors in x\n",
    "        err_y_arr = []  # List to store errors in y\n",
    "\n",
    "        for idx in range(X_Y_GT.shape[0]):\n",
    "            e_x = X_Y_GT[idx, 0] - X_Y_est[idx, 0]\n",
    "            e_y = X_Y_GT[idx, 1] - X_Y_est[idx, 1]\n",
    "            err_x_arr.append(e_x)\n",
    "            err_y_arr.append(e_y)\n",
    "            if idx > starting_point:\n",
    "                e_squared_list.append(e_x ** 2 + e_y ** 2)  # Calculate squared error\n",
    "                curr_E = e_x + e_y  # Calculate current error\n",
    "                if curr_E > maxE:  # Update max error\n",
    "                    maxE = curr_E\n",
    "                num_of_elements += 1\n",
    "\n",
    "        RMSE = np.sqrt(np.sum(e_squared_list) / num_of_elements) if num_of_elements > 0 else 0.0  # Calculate RMSE\n",
    "\n",
    "        return RMSE, maxE, np.array(err_x_arr), np.array(err_y_arr)\n",
    "\n",
    "    def Q1(self):\n",
    "        \"\"\"\n",
    "        This function runs the code of question 1 of the project.\n",
    "        Load data from the KITTI dataset, add noise to the ground truth GPS values,\n",
    "        and apply a Kalman filter to the noisy data (enu).\n",
    "        \"\"\"\n",
    "        locations_GT = self.enu[:, 0:2]\n",
    "\n",
    "        # b, c\n",
    "        lla_coordinates = build_LLA_GPS_trajectory(self.dataset)\n",
    "        if self.display_results:\n",
    "            graphs.plot_trajectory_and_height(lla_coordinates, \"Longitude Latitude world coordinate trajectory\",\n",
    "                                              'longitude[deg]', 'latitude[deg]',\n",
    "                                              \"Altitude per frame in the world coordinate trajectory\", 'frame[Number]',\n",
    "                                              'Altitude[m]')\n",
    "            save_graphs(self.fig_dir_path, \"ground-truth GPS trajectory LLA\")\n",
    "\n",
    "            graphs.plot_trajectory_and_height(self.enu, \"X-East Y-North coordinate trajectory\", 'X-East[m]',\n",
    "                                              'Y-North[m]',\n",
    "                                              \"Height per frame in X Y coordinate trajectory\", 'frame[Number]',\n",
    "                                              'Height[m]')\n",
    "            save_graphs(self.fig_dir_path, \"ground-truth GPS trajectory ENU\")\n",
    "\n",
    "            # d\n",
    "            # Add a Gaussian noise to the ground-truth GPS data\n",
    "            graphs.plot_trajectory_with_noise(self.enu, np.stack([self.enu_noise[:, 0], self.enu_noise[:, 1]], axis=-1),\n",
    "                                              'Trajectory in local coordinates(ENU) with and without noise',\n",
    "                                              'X-East[m]', 'Y-North[m]', 'GT Trajectory(ENU)', 'Noised Trajectory(ENU)')\n",
    "            save_graphs(self.fig_dir_path, \"Comparison of the ENU path with and noise\")\n",
    "\n",
    "        ### e. calibration of Kalman filter ###\n",
    "        sigma_n_values = np.arange(0, 2, 0.1)\n",
    "        Rmse_vec = []\n",
    "        maxE_vec = []\n",
    "        for sigma_n in sigma_n_values:\n",
    "            kf = KalmanFilter(self.enu_noise,\n",
    "                              self.dataset.get_timestamps(),\n",
    "                              self.yaw_vf_vl_wz[:, 1],\n",
    "                              self.yaw_vf_vl_wz[:, 2],\n",
    "                              self.sigma_xy,\n",
    "                              sigma_n,\n",
    "                              self.sigma_vx,\n",
    "                              self.sigma_vy,\n",
    "                              self.k,\n",
    "                              False)\n",
    "\n",
    "            locations_kf, kf_sigma = kf.run()\n",
    "            RMSE, maxE, err_x_arr, err_y_arr = ProjectQuestions1.calc_RMSE_maxE(locations_GT, locations_kf)\n",
    "            Rmse_vec.append(RMSE)\n",
    "            maxE_vec.append(maxE)\n",
    "\n",
    "        min_idx_rmse = np.argmin(Rmse_vec)\n",
    "        min_idx_maxE = np.argmin(maxE_vec)\n",
    "\n",
    "        fig_e, axes_e = plt.subplots(1, 2, figsize=(12, 8))\n",
    "        axes_e[0].plot(sigma_n_values, Rmse_vec)\n",
    "        axes_e[0].scatter(sigma_n_values[min_idx_rmse], Rmse_vec[min_idx_rmse])\n",
    "        axes_e[0].set_title('RMSE vs sigma_n values \\n min for sigma_n = ' + str(round(sigma_n_values[min_idx_rmse], 3)))\n",
    "        axes_e[0].set(xlabel='sigma_n', ylabel='Rmse [m]')\n",
    "        axes_e[0].grid()\n",
    "        axes_e[1].plot(sigma_n_values, maxE_vec)\n",
    "        axes_e[1].scatter(sigma_n_values[min_idx_maxE], maxE_vec[min_idx_maxE])\n",
    "        axes_e[1].set_title('maxE vs sigma_n values \\n min for sigma_n = ' + str(round(sigma_n_values[min_idx_maxE], 3)))\n",
    "        axes_e[1].set(xlabel='sigma_n', ylabel='maxE [m]')\n",
    "        axes_e[1].grid()\n",
    "        fig_e.tight_layout()\n",
    "        file_name = \"{}/{}.png\".format(self.fig_dir_path, f\"Kalman_filter_calibration\")\n",
    "        fig_e.savefig(file_name)\n",
    "\n",
    "        # f - Kalman\n",
    "        # Dead Reckoning OFF\n",
    "        kalman_filter = KalmanFilter(self.enu_noise,\n",
    "                                     self.dataset.get_timestamps(),\n",
    "                                     self.yaw_vf_vl_wz[:, 1],\n",
    "                                     self.yaw_vf_vl_wz[:, 2],\n",
    "                                     self.sigma_xy,\n",
    "                                     self.sigma_n,\n",
    "                                     self.sigma_vx,\n",
    "                                     self.sigma_vy,\n",
    "                                     self.k,\n",
    "                                     False)\n",
    "\n",
    "        locations_kf, kf_sigma = kalman_filter.run()\n",
    "        self.locations_kf = locations_kf\n",
    "\n",
    "        if self.display_results:\n",
    "            graphs.plot_trajectory_comparison(locations_GT, locations_kf)\n",
    "            save_graphs(self.fig_dir_path, f\"Comparison of the ground truth trajectory and the filtered trajectory (KF)\")\n",
    "\n",
    "        # RMSE, maxE, err_x_arr, err_y_arr\n",
    "        RMSE, maxE, err_x_arr, err_y_arr = ProjectQuestions1.calc_RMSE_maxE(locations_GT, locations_kf)\n",
    "\n",
    "        # Dead Reckoning ON\n",
    "        kalman_filter = KalmanFilter(self.enu_noise,\n",
    "                                     self.dataset.get_timestamps(),\n",
    "                                     self.yaw_vf_vl_wz[:, 1],\n",
    "                                     self.yaw_vf_vl_wz[:, 2],\n",
    "                                     self.sigma_xy,\n",
    "                                     self.sigma_n,\n",
    "                                     self.sigma_vx,\n",
    "                                     self.sigma_vy,\n",
    "                                     self.k,\n",
    "                                     True)\n",
    "\n",
    "        locations_kf_dr, kf_sigma_dr = kalman_filter.run()\n",
    "\n",
    "        if self.display_results:\n",
    "            print(f'maxE={maxE}, RMSE={RMSE}')\n",
    "            graphs.plot_trajectory_comparison_dead_reckoning(locations_GT, locations_kf, locations_kf_dr)\n",
    "            save_graphs(self.fig_dir_path, f\"trajectory_comparison_dead_reckoning\")\n",
    "            graphs.plot_error([err_x_arr, np.sqrt(kf_sigma[:, 0, 0])], [err_y_arr, np.sqrt(kf_sigma[:, 2, 2])])\n",
    "            save_graphs(self.fig_dir_path, f\"plot_trajectory_error\")\n",
    "\n",
    "        if self.animation_results:\n",
    "            print(\"wait...\")\n",
    "            ani = graphs.build_animation(locations_GT, locations_kf_dr, locations_kf,\n",
    "                                         kf_sigma[:, ::2, ::2].reshape(kf_sigma.shape[0], -1),\n",
    "                                         'KF Trajectory estimation - constant velocity with dead reckoning',\n",
    "                                         'X-East[m]', 'Y-North[m]', 'GT', 'Dead Reckoning', 'KF')\n",
    "            graphs.save_animation(ani, self.fig_dir_path, \"kf_predict_with_dead_reckoning\")\n",
    "            print(\"Done!\")\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "    def run(self):\n",
    "        self.Q1()\n",
    "        print(\"Successfully finished. All data saved in {}\".format(self.fig_dir_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxE=4.304851892707902, RMSE=1.6260814977429983\n",
      "wait...\n",
      "Creating animation\n",
      "Saving animation\n",
      "Animation saved\n",
      "Done!\n",
      "Successfully finished. All data saved in C:\\Users\\Nadav/Results_Q1/\n"
     ]
    }
   ],
   "source": [
    "# Run Kalman Filter!\n",
    "\n",
    "display_results=True\n",
    "animation_results=True\n",
    "\n",
    "project = ProjectQuestions1(dataset,display_results,animation_results)\n",
    "project.run()\n",
    "locations_kf=project.locations_kf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B\n",
    "## Localization based on Extended Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the #TODO sections within the ExtendedKalmanFilter class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_angle(angle):\n",
    "    \"\"\"\n",
    "    Normalize an angle to the range [-pi, pi).\n",
    "    \n",
    "    Args:\n",
    "        angle (float): angle in radians.\n",
    "        \n",
    "    Returns:\n",
    "        float: normalized angle in radians.\n",
    "    \"\"\"\n",
    "    while angle > np.pi:\n",
    "        angle -= 2.0 * np.pi\n",
    "    while angle < -np.pi:\n",
    "        angle += 2.0 * np.pi\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedKalmanFilter:\n",
    "    \"\"\"\n",
    "    class for the implementation of the extended Kalman filter\n",
    "    \"\"\"\n",
    "    def __init__(self, enu_noise, yaw_vf_wz_noise, times, sigma_xy, sigma_theta, sigma_vf, sigma_wz, k, is_dead_reckoning, dead_reckoning_start_sec=5.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            enu_noise: enu data with noise\n",
    "            times: elapsed time in seconds from the first timestamp in the sequence\n",
    "            sigma_xy: sigma in the x and y axis as provided in the question\n",
    "            sigma_n: hyperparameter used to fine tune the filter\n",
    "            yaw_vf_wz: the yaw, forward velocity and angular change rate to be used (either non noisy or noisy, depending on the question)\n",
    "            sigma_theta: sigma of the heading\n",
    "            sigma_vf: sigma of the forward velocity\n",
    "            sigma_wz: sigma of the angular change rate\n",
    "            k: hyper parameter to fine tune the filter\n",
    "            is_dead_reckoning: should dead reckoning be applied after 5.0 seconds when applying the filter\n",
    "            dead_reckoning_start_sec: from what second do we start applying dead reckoning, used for experimentation only\n",
    "        \"\"\"\n",
    "        self.enu_noise = enu_noise\n",
    "        self.yaw_vf_wz_noise = yaw_vf_wz_noise\n",
    "        self.times = times\n",
    "        self.sigma_xy = sigma_xy\n",
    "        self.sigma_theta = sigma_theta\n",
    "        self.sigma_vf = sigma_vf\n",
    "        self.sigma_wz = sigma_wz\n",
    "        self.k = k\n",
    "        self.is_dead_reckoning = is_dead_reckoning\n",
    "        self.dead_reckoning_start_sec = dead_reckoning_start_sec\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_RMSE_maxE(X_Y_GT, YAW_GT, X_Y_est, YAW_est):\n",
    "        \"\"\"\n",
    "        That function calculates RMSE and maxE\n",
    "\n",
    "        Args:\n",
    "            X_Y_GT (np.ndarray): ground truth values of x and y\n",
    "            X_Y_est (np.ndarray): estimated values of x and y\n",
    "\n",
    "        Returns:\n",
    "            (float, float): RMSE, maxE\n",
    "        \"\"\"\n",
    "        start_point = 100  # TODO Set the starting point for calculations\n",
    "        maxE = -1   # Initialize max error variable\n",
    "        num_of_elements = 0  # Initialize count of elements\n",
    "        e_squared_list = []  # List to store squared errors\n",
    "        err_x_arr = []  # List to store errors in x\n",
    "        err_y_arr = []  # List to store errors in y\n",
    "        err_yaw_arr = []  # List to store errors in yaw\n",
    "\n",
    "        for idx in range(X_Y_GT.shape[0]):\n",
    "            e_x = X_Y_GT[idx, 0] - X_Y_est[idx, 0]\n",
    "            e_y = X_Y_GT[idx, 1] - X_Y_est[idx, 1]\n",
    "            e_yaw = normalize_angle(YAW_GT[idx] - YAW_est[idx])\n",
    "            err_x_arr.append(e_x)\n",
    "            err_y_arr.append(e_y)\n",
    "            err_yaw_arr.append(e_yaw)\n",
    "            if idx > start_point:\n",
    "                e_squared_list.append(e_x ** 2 + e_y ** 2)  # TODO calculate squared error (hint use e_x,e_y)\n",
    "                curr_E = e_x + e_y  # TODO Calculate current error (hint use e_x,e_y)\n",
    "                if curr_E > maxE:  # Update max error\n",
    "                    maxE = curr_E\n",
    "                num_of_elements += 1\n",
    "\n",
    "        RMSE = np.sqrt(np.sum(e_squared_list) / num_of_elements) if num_of_elements > 0 else 0.0  # Calculate RMSE\n",
    "        return RMSE, maxE, np.array(err_x_arr), np.array(err_y_arr), np.array(err_yaw_arr)\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the Kalman filter\n",
    "\n",
    "        outputs: enu_kf, covs\n",
    "        \"\"\"\n",
    "        P0 = np.array([\n",
    "            [self.k * (self.sigma_xy ** 2), 0, 0],\n",
    "            [0, self.k * (self.sigma_xy * self.sigma_theta), 0],\n",
    "            [0, 0, self.k * (self.sigma_theta ** 2)]\n",
    "        ], dtype='float32')\n",
    "\n",
    "        H = np.array([[1, 0, 0], [0, 1, 0]])\n",
    "\n",
    "        R = np.array([[self.sigma_vf ** 2, 0], [0, self.sigma_wz ** 2]], dtype='float32')\n",
    "\n",
    "        R_gal = np.zeros((3, 3), dtype='float32')\n",
    "        R_gal[0, 0] = 0.00001\n",
    "        R_gal[1, 1] = 0.00001\n",
    "        R_gal[2, 2] = 0.00001\n",
    "\n",
    "        Q = np.array([[self.sigma_xy ** 2, 0], [0, self.sigma_xy ** 2]], dtype='float32')\n",
    "\n",
    "        muo_tO = np.array([[self.enu_noise[0, 0]], [self.enu_noise[0, 1]], [self.yaw_vf_wz_noise[0][0]]], dtype='float32')\n",
    "        sigma_t_minus1 = P0\n",
    "\n",
    "        locations_kf = []\n",
    "        sigma_kf = []\n",
    "        for idx, (enu_point, curr_timestemp, yaw_vf_wz_noise) in enumerate(zip(self.enu_noise, self.times, self.yaw_vf_wz_noise)):\n",
    "            if idx == 0:\n",
    "                muo_t_minus1 = muo_tO.flatten()\n",
    "                start_timestemp = curr_timestemp\n",
    "                prev_timestemp = curr_timestemp\n",
    "                sigma_t_minus1 = P0\n",
    "                locations_kf.append(muo_t_minus1)\n",
    "                sigma_kf.append(sigma_t_minus1)\n",
    "                continue\n",
    "\n",
    "            z_t = np.array([enu_point[0], enu_point[1]])\n",
    "            delta_t = (curr_timestemp - prev_timestemp).total_seconds()\n",
    "            time_since_start = (curr_timestemp - start_timestemp).total_seconds()\n",
    "\n",
    "            vf_t = yaw_vf_wz_noise[1]\n",
    "            w_t = yaw_vf_wz_noise[2]\n",
    "            ratio = vf_t / w_t\n",
    "            \n",
    "            G = np.array([\n",
    "                [1, 0, float(-ratio * np.cos(muo_t_minus1[2]) + ratio * np.cos(muo_t_minus1[2] + w_t * delta_t))],\n",
    "                [0, 1, float(-ratio * np.sin(muo_t_minus1[2]) + ratio * np.sin(muo_t_minus1[2] + w_t * delta_t))],\n",
    "                [0, 0, 1]\n",
    "            ])\n",
    "\n",
    "            non_linear_muo = np.array([\n",
    "                -ratio * np.sin(muo_t_minus1[2]) + ratio * np.sin(muo_t_minus1[2] + w_t * delta_t),\n",
    "                ratio * np.cos(muo_t_minus1[2]) - ratio * np.cos(muo_t_minus1[2] + w_t * delta_t),\n",
    "                w_t * delta_t\n",
    "            ], dtype='float32')\n",
    "\n",
    "            V = np.array([\n",
    "                [(-1 / w_t) * np.sin(muo_t_minus1[2]) + (1 / w_t) * np.sin(muo_t_minus1[2] + w_t * delta_t), \n",
    "                 (vf_t / (w_t ** 2)) * np.sin(muo_t_minus1[2]) - (vf_t / (w_t ** 2)) * np.sin(muo_t_minus1[2] + w_t * delta_t) + (vf_t / w_t) * np.cos(muo_t_minus1[2] + w_t * delta_t) * delta_t],\n",
    "                [(1 / w_t) * np.cos(muo_t_minus1[2]) - (1 / w_t) * np.cos(muo_t_minus1[2] + w_t * delta_t), \n",
    "                 (-vf_t / (w_t ** 2)) * np.cos(muo_t_minus1[2]) + (vf_t / (w_t ** 2)) * np.cos(muo_t_minus1[2] + w_t * delta_t) + (vf_t / w_t) * np.sin(muo_t_minus1[2] + w_t * delta_t) * delta_t],\n",
    "                [0, delta_t]\n",
    "            ], dtype='float32')\n",
    "\n",
    "            muo_t_bar = muo_t_minus1 + non_linear_muo\n",
    "            sigma_t_bar = G @ sigma_t_minus1 @ G.T + V @ R @ V.T + R_gal\n",
    "\n",
    "            K_t = sigma_t_bar @ H.T @ np.linalg.inv(H @ sigma_t_bar @ H.T + Q)\n",
    "                        \n",
    "            if time_since_start >= self.dead_reckoning_start_sec and self.is_dead_reckoning:\n",
    "                \n",
    "                K_t = np.zeros_like(K_t)\n",
    "            muo_t = muo_t_bar + K_t @ (z_t - H @ muo_t_bar)\n",
    "            sigma_t = (np.eye(3) - K_t @ H) @ sigma_t_bar\n",
    "\n",
    "            muo_t_minus1 = muo_t\n",
    "            muo_t_minus1[-1] = normalize_angle(muo_t_minus1[-1])\n",
    "            prev_timestemp = curr_timestemp\n",
    "            sigma_t_minus1 = sigma_t\n",
    "            locations_kf.append(muo_t)\n",
    "            sigma_kf.append(sigma_t)\n",
    "\n",
    "        return np.array(locations_kf), np.array(sigma_kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the #TODO sections within the ProjectQuestions2 class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectQuestions2:\n",
    "    def __init__(self, dataset,display_results,save_animation,locations_kf):\n",
    "        \"\"\"\n",
    "        Given a Loaded Kitti data set with the following ground truth values: tti dataset and adds noise to GT-gps values\n",
    "        - lat: latitude [deg]\n",
    "        - lon: longitude [deg]\n",
    "        - yaw: heading [rad]\n",
    "        - vf: forward velocity parallel to earth-surface [m/s]\n",
    "        - wz: angular rate around z axis [rad/s]\n",
    "        Builds the following np arrays:\n",
    "        - enu - lla converted to enu data\n",
    "        - times - for each frame, how much time has elapsed from the previous frame\n",
    "        - yaw_vf_wz - yaw, forward velocity and angular change rate\n",
    "        - enu_noise - enu with Gaussian noise (sigma_xy=3 meters)\n",
    "        - yaw_vf_wz_noise - yaw_vf_wz with Gaussian noise in vf (sigma 2.0) and wz (sigma 0.2)\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.display_results=display_results\n",
    "        self.save_animation=save_animation\n",
    "        self.locations_kf=locations_kf\n",
    "        self.enu, self.times, self.yaw_vf_vl_wz = build_GPS_trajectory(self.dataset)\n",
    "        self.location_GT = self.enu[:,0:2]\n",
    "        # # # add noise to the trajectory\n",
    "        self.sigma_xy = 3\n",
    "        \n",
    "        e_noised = add_gaussian_noise(self.enu[:, 0], self.sigma_xy)\n",
    "        n_noised = add_gaussian_noise(self.enu[:, 1], self.sigma_xy)\n",
    "        u_noised = add_gaussian_noise(self.enu[:, 2], self.sigma_xy)\n",
    "        self.enu_noise = np.stack([e_noised, n_noised, u_noised], axis=-1)\n",
    "\n",
    "        self.sigma_theta = 0.18  # Set value for sigma_theta\n",
    "        self.sigma_vf = 2 # Set value for sigma_vf\n",
    "        self.sigma_wz = 0.2  # Set value for sigma_wz\n",
    "        self.k =  1\n",
    "        \n",
    "        yaw_noised = add_gaussian_noise(self.yaw_vf_vl_wz[:, 0], self.sigma_theta)\n",
    "        vf_noised = add_gaussian_noise(self.yaw_vf_vl_wz[:, 1], self.sigma_vf)\n",
    "        wz_noised = add_gaussian_noise(self.yaw_vf_vl_wz[:, 3], self.sigma_wz)\n",
    "        self.yaw_vf_wz_noise = np.stack([yaw_noised, vf_noised, wz_noised], axis=-1)\n",
    "\n",
    "        self.fig_dir_path = os.getcwd() + \"/Results_Q2/\"\n",
    "        if not os.path.exists(self.fig_dir_path):\n",
    "            os.makedirs(self.fig_dir_path)\n",
    "\n",
    "    \n",
    "    def Q2(self):\n",
    "\n",
    "        \"\"\"\n",
    "        That function runs the code of question 2 of the project.\n",
    "        Load data from the KITTI dataset, add noise to the ground truth GPS values, yaw rate, and velocities, and apply a Extended Kalman filter to the noisy data.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.display_results:\n",
    "            # c, d, e, f -          # plot vf and wz with and without noise\n",
    "            graphs.plot_yaw_yaw_rate_fv(self.yaw_vf_vl_wz[:,0],self.yaw_vf_vl_wz[:,3],self.yaw_vf_vl_wz[:,1])\n",
    "            save_graphs(self.fig_dir_path,F\"Yaw_Yaw_rate_fv\")\n",
    "\n",
    "            graphs.plot_vf_wz_with_and_without_noise(self.yaw_vf_vl_wz[:,[0,1,3]],self.yaw_vf_wz_noise)\n",
    "            save_graphs(self.fig_dir_path,F\"vf_wz_with_and_without_noise\")\n",
    "\n",
    "        ekf = ExtendedKalmanFilter(self.enu_noise,\n",
    "                                   self.yaw_vf_wz_noise,\n",
    "                                   self.dataset.get_timestamps(),\n",
    "                                   self.sigma_xy,\n",
    "                                   self.sigma_theta,\n",
    "                                   self.sigma_vf,\n",
    "                                   self.sigma_wz,\n",
    "                                   self.k,\n",
    "                                   False)\n",
    "        \n",
    "        locations_ekf_x_y_yaw, sigma_x_xy_yx_y_t = ekf.run()\n",
    "        locations_ekf = locations_ekf_x_y_yaw[:,0:2]\n",
    "        self.locations_ekf = locations_ekf\n",
    "        RMSE, maxE, err_x_arr, err_y_arr, err_yaw_arr = ekf.calc_RMSE_maxE(self.location_GT, self.yaw_vf_vl_wz[:,0], locations_ekf, locations_ekf_x_y_yaw[:,2])\n",
    "\n",
    "        if self.display_results:\n",
    "            print(f'maxE{maxE}, RMSE={RMSE}')\n",
    "            graphs.plot_trajectory_comparison(self.location_GT,locations_ekf)\n",
    "            save_graphs(self.fig_dir_path,f\"plot_trajectory_comparison\")\n",
    "\n",
    "            graphs.plot_error([err_x_arr,np.sqrt(sigma_x_xy_yx_y_t[:,0,0])],[err_y_arr,np.sqrt(sigma_x_xy_yx_y_t[:,1,1])],[err_yaw_arr,np.sqrt(sigma_x_xy_yx_y_t[:,2,2])])\n",
    "           # save_graphs(self.fig_dir_path,\"ground-truth GPS trajectory ENU\")\n",
    "            save_graphs(self.fig_dir_path,f\"plot_error_EKF_vs_GT\")\n",
    "\n",
    "        ekf = ExtendedKalmanFilter(self.enu_noise,\n",
    "                                   self.yaw_vf_wz_noise,\n",
    "                                   self.dataset.get_timestamps(),\n",
    "                                   self.sigma_xy,\n",
    "                                   self.sigma_theta,\n",
    "                                   self.sigma_vf,\n",
    "                                   self.sigma_wz,\n",
    "                                   self.k,\n",
    "                                   True)\n",
    "\n",
    "        locations_ekf_dr, ekf_sigma_dr = ekf.run()\n",
    "        locations_ekf_dr_x_y_yaw, ekf_sigma_dr = ekf.run()\n",
    "        locations_ekf_dr = locations_ekf_dr_x_y_yaw[:,0:2]\n",
    "\n",
    "        if self.display_results:\n",
    "            graphs.plot_trajectory_comparison_dead_reckoning(self.location_GT, locations_ekf, locations_ekf_dr)\n",
    "            save_graphs(self.fig_dir_path,f\"plot_trajectory_comparison_dead_reckoning\")\n",
    "            graphs.plot_trajectory_comparison_kf_ekf(self.location_GT, self.locations_ekf, self.locations_kf)\n",
    "            save_graphs(self.fig_dir_path,f\"trajectory_comparison_kf_ekf\")\n",
    "     \n",
    "\n",
    "        if self.save_animation:\n",
    "            print(\"wait...\")\n",
    "            ani = graphs.build_animation(self.location_GT, locations_ekf_dr, locations_ekf, sigma_x_xy_yx_y_t[:, :2, :2].reshape(sigma_x_xy_yx_y_t.shape[0], -1),'EKF Trajectory estimation - constant velocity with dead reckoning', 'X-East[m]', 'Y-North[m]', 'GT', 'Dead Reckoning', 'EKF') #hint- graphs.build_animation)\n",
    "            \n",
    "            graphs.save_animation(ani, self.fig_dir_path, \"EKF_predict_with_dead_reckoning\")\n",
    "            print(\"Done!...\")\n",
    "            plt.close()\n",
    "\n",
    "    def get_odometry(self, sensor_data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sensor_data: map from a tuple (frame number, type) where type is either ‘odometry’ or ‘sensor’.\n",
    "            Odometry data is given as a map containing values for ‘r1’, ‘t’ and ‘r2’ – the first angle, the translation and the second angle in the odometry model respectively.\n",
    "            Sensor data is given as a map containing:\n",
    "              - ‘id’ – a list of landmark ids (starting at 1, like in the landmarks structure)\n",
    "              - ‘range’ – list of ranges, in order corresponding to the ids\n",
    "              - ‘bearing’ – list of bearing angles in radians, in order corresponding to the ids\n",
    "\n",
    "        Returns:\n",
    "            numpy array of of dim [num of frames X 3]\n",
    "            first two components in each row are the x and y in meters\n",
    "            the third component is the heading in radians\n",
    "        \"\"\"\n",
    "        num_frames = len(sensor_data) // 2\n",
    "        state = np.array([[0, 0, 0]], dtype=float).reshape(1, 3)\n",
    "        for i in range(num_frames):\n",
    "            curr_odometry = sensor_data[i, 'odometry']\n",
    "            t = np.array([\n",
    "                curr_odometry['t'] * np.cos(state[-1, 2] + curr_odometry['r1']),\n",
    "                curr_odometry['t'] * np.sin(state[-1, 2] + curr_odometry['r1']),\n",
    "                curr_odometry['r1'] + curr_odometry['r2']\n",
    "            ]).reshape(3, 1)\n",
    "            new_pos = state[-1, :].reshape(3, 1) + t\n",
    "            state = np.concatenate([state, new_pos.reshape(1, 3)], axis=0)\n",
    "        return state\n",
    "\n",
    "    \n",
    "    def run(self):\n",
    "        self.Q2()\n",
    "        print(\"Successfully finished. All data saved in {}\".format(self.fig_dir_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxE3.5285106239445625, RMSE=1.3169028684098618\n",
      "wait...\n",
      "Creating animation\n",
      "Saving animation\n",
      "Animation saved\n",
      "Done!...\n",
      "Successfully finished. All data saved in C:\\Users\\Nadav/Results_Q2/\n"
     ]
    }
   ],
   "source": [
    "display_results=True\n",
    "save_animation=True\n",
    "project = ProjectQuestions2(dataset,display_results,save_animation,locations_kf)\n",
    "project.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "22d54b2afd460569b9e9050ca66571082a0929281e5b28d20c6fd75528a62769"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
