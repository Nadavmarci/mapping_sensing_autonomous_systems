{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping and Perception for an autonomous robot (0510-7951)\n",
    "\n",
    "### 2024/B\n",
    "\n",
    "### Written by Roy Orfaig\n",
    "\n",
    "---\n",
    "\n",
    "SLAM: Simulatinoud Localization And Mapping!\n",
    "\n",
    "-------------------------------------\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Fill in the code the \"TODO\" section\n",
    "2. Answer the question inside the sections\n",
    "3. **Please copy all the results to the report:**\n",
    "  - Outputs- Images, tables, scores,etc\n",
    "  - Performace, analysis and your explanations.\n",
    "  - Attach the completed notebook to the report package.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nadav\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "project_path = r\"C:\\Users\\Nadav\\Desktop\\TAU\\מיפוי וחישה למערכות אוטונמיות\\Project_3\\EKF-SLAM\"\n",
    "sys.path.append(project_path)\n",
    "\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.patches import Ellipse\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pykitti\n",
    "from math import sin, cos, sqrt\n",
    "\n",
    "import graphs_slam\n",
    "from graphs_slam import percentage_within_boundary,normalize_angle_radians,plot_state,save_graphs,plot_error\n",
    "\n",
    "from data_preparation import *\n",
    "from utils.ellipse import draw_prob_ellipse\n",
    "from utils.draw_robot import draw_robot\n",
    "from utils.misc_tools import error_ellipse\n",
    "from utils.ellipse import draw_ellipse\n",
    "from utils.misc_tools import error_ellipse\n",
    "from data_loader_slam import DataSLAMLoader\n",
    "from data_preparation import normalize_angle, normalize_angles_array\n",
    "from utils import read_data\n",
    "\n",
    "from utils.ellipse import draw_prob_ellipse\n",
    "from utils.draw_robot import draw_robot\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student name+ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nadav Marcinao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 305165698"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont touch this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSLAMLoader:\n",
    "    def __init__(self, basedir,dat_dir):\n",
    "        self.dat_dir = dat_dir\n",
    "    \n",
    "    def load_landmarks(self):\n",
    "        # read landmarks(SLAM)\n",
    "        world_path = os.path.join(self.dat_dir, \"world.dat\")\n",
    "        return read_data.read_world(world_path)\n",
    "    \n",
    "    def load_sensor_data(self):\n",
    "        # read sensor data(SLAM)\n",
    "        sensor_data_path = os.path.join(self.dat_dir, \"sensor_data.dat\")\n",
    "        return read_data.read_sensor_data(sensor_data_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"/Users/Nadav/Desktop/TAU/מיפוי וחישה למערכות אוטונמיות/Project_3/EKF-SLAM\" \n",
    "dat_dir = os.path.join(basedir,\"data\") \n",
    "\n",
    "dataset = DataSLAMLoader(basedir, dat_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simultaneous localization and mapping  (SLAM)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the #TODO sections within the ExtendedKalmanFilterSLAM class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedKalmanFilterSLAM:\n",
    "    start_idx = 20 # ignore the first samples for the errors calculations\n",
    "    def __init__(self, sigma_x_y_theta, variance_r1_t_r2, variance_r_phi, k):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            variance_x_y_theta: variance in x, y and theta respectively\n",
    "            variance_r1_t_r2: variance in rotation1, translation and rotation2 respectively\n",
    "            variance_r_phi: variance in the range and bearing\n",
    "        \"\"\"\n",
    "\n",
    "        self.sigma_x_y_theta = sigma_x_y_theta\n",
    "        self.variance_r_phi = variance_r_phi\n",
    "\n",
    "        # additional params\n",
    "        self.init_inf_val = 100 #TODO (hint - put value as the max size of the grid)\n",
    "        self.R_tilde = np.diag(variance_r1_t_r2)\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_RMSE_maxE(X_Y_GT, X_Y_est):\n",
    "        X_Y_diff = X_Y_GT[ExtendedKalmanFilterSLAM.start_idx:, :2] - X_Y_est[ExtendedKalmanFilterSLAM.start_idx:, :2]\n",
    "        RMSE = np.linalg.norm(X_Y_diff) / np.sqrt(len(X_Y_GT) - ExtendedKalmanFilterSLAM.start_idx)\n",
    "        maxE = np.max(np.abs(X_Y_diff[:,0]) + np.abs(X_Y_diff[:,1]))\n",
    "        return RMSE, maxE ,X_Y_diff\n",
    "\n",
    "    def predict(self, mu_prev, sigma_prev, u, N):\n",
    "        # Perform the prediction step of the EKF\n",
    "        # u[0]=translation, u[1]=rotation1, u[2]=rotation2\n",
    "\n",
    "        delta_trans, delta_rot1, delta_rot2 = u['t'], u['r1'], u['r2']\n",
    "        theta_prev = mu_prev[2]\n",
    "\n",
    "\n",
    "        F = np.hstack((np.eye(3), np.zeros((3, 2*N))))\n",
    "        G_x = np.eye(3) + np.array([[0, 0, -1*delta_trans*sin(theta_prev + delta_rot1)], [0, 0, delta_trans*cos(theta_prev + delta_rot1)], [0, 0, 0]])\n",
    "        G = np.eye(3+2*N); G[0:3, 0:3] = G_x\n",
    "        V = np.array([[-1*delta_trans*sin(theta_prev+delta_rot1), cos(theta_prev+delta_rot1), 0],\n",
    "                      [delta_trans*cos(theta_prev+delta_rot1), sin(theta_prev+delta_rot1), 0],\n",
    "                      [1, 0, 1]])\n",
    "\n",
    "\n",
    "        # Calculate R with the added Q_additional\n",
    "        R = F.T @ V @ self.R_tilde @ V.T @ F #TODO (hint: use F.T , V , self.R_tilde , V.T , F )\n",
    "\n",
    "        odometry_model_next_step=np.array([[delta_trans*cos(theta_prev + delta_rot1)], [delta_trans*sin(theta_prev + delta_rot1)],[delta_rot1 + delta_rot2]])\n",
    "\n",
    "        mu_est = mu_prev + F.T @ odometry_model_next_step\n",
    "        sigma_est = G @ sigma_prev @ G.T + R #TODO (hint: use G , sigma_prev ,G.T,R)\n",
    "        return mu_est, sigma_est\n",
    "\n",
    "\n",
    "    def update(self, mu_pred, sigma_pred, z, observed_landmarks, N):\n",
    "        # Perform filter update (correction) for each odometry-observation pair read from the data file.\n",
    "        mu = mu_pred.copy()\n",
    "        sigma = sigma_pred.copy()\n",
    "        theta = mu[2][0] # the [0] is used to make theta a float and not an 1x1 array\n",
    "\n",
    "        m = len(z[\"id\"])\n",
    "        Z = np.zeros(2 * m)\n",
    "        z_hat = np.zeros(2 * m)\n",
    "        H = None\n",
    "\n",
    "        for idx in range(m):\n",
    "            j = z[\"id\"][idx] - 1\n",
    "            r = z[\"range\"][idx]\n",
    "            phi = z[\"bearing\"][idx]\n",
    "\n",
    "            mu_j_x_idx = 3 + j*2\n",
    "            mu_j_y_idx = 4 + j*2\n",
    "            Z_j_x_idx = idx*2\n",
    "            Z_j_y_idx = 1 + idx*2\n",
    "\n",
    "            if observed_landmarks[j] == False:\n",
    "                mu[mu_j_x_idx: mu_j_y_idx + 1] = mu[0:2] + np.array([r * cos(phi + theta), r * sin(phi + theta)]).reshape(-1, 1)\n",
    "                observed_landmarks[j] = True\n",
    "\n",
    "            Z[Z_j_x_idx : Z_j_y_idx + 1] = np.array([r, phi])\n",
    "\n",
    "            delta = mu[mu_j_x_idx : mu_j_y_idx + 1] - mu[0 : 2]\n",
    "            delta_x , delta_y = delta.ravel()\n",
    "            q = float((delta.T) @ delta)\n",
    "            # based on formula from lecture, delta_x, delta_y = delta; mu_bar_t_theta = mu[2]\n",
    "            z_hat[Z_j_x_idx : Z_j_y_idx + 1] = np.array([sqrt(q), normalize_angle(np.arctan2(delta_y, delta_x)) - theta])\n",
    "\n",
    "            I = np.diag(5*[1])\n",
    "            F_j = np.hstack((I[:,:3], np.zeros((5, 2*j)), I[:,3:], np.zeros((5, 2*N-2*(j+1)))))\n",
    "\n",
    "            sqrt_q = sqrt(q)\n",
    "            Hi = (1/q) * np.array([[-1*sqrt_q*delta_x, -1*sqrt_q*delta_y, 0, sqrt_q*delta_x, sqrt_q*delta_y],[delta_y, -1*delta_x, -1*q, -1*delta_y, delta_x]]) @ F_j\n",
    "\n",
    "            if H is None:\n",
    "                H = Hi.copy()\n",
    "            else:\n",
    "                H = np.vstack((H, Hi))\n",
    "\n",
    "        Q = self.k * np.diag(m * self.variance_r_phi)\n",
    "\n",
    "        K = sigma_pred @ H.T @ np.linalg.inv(H @ sigma_pred @ H.T + Q) #TODO (hint- sigma_pred, H.T ,H , sigma_pred , H.T, Q)\n",
    "\n",
    "\n",
    "        diff = Z - z_hat #TODO (hint- use Z , z_hat)\n",
    "        diff[1::2] = normalize_angles_array(diff[1::2])\n",
    "\n",
    "        mu =  mu + K @ diff.reshape(-1, 1) #TODO (hint- use mu,K, diff)\n",
    "        sigma = (np.eye(sigma_pred.shape[0]) - K @ H) @ sigma_pred #TODO (hint- use K, H,sigma_pred)\n",
    "\n",
    "        mu[2] = normalize_angle(float(mu[2]))\n",
    "\n",
    "        return mu, sigma, observed_landmarks\n",
    "\n",
    "    def run(self, sensor_data_gt, sensor_data_noised, landmarks, ax):\n",
    "        # Get the number of landmarks in the map\n",
    "        N = len(landmarks)\n",
    "\n",
    "        # Initialize belief:\n",
    "        # mu: 2N+3x1 vector representing the mean of the normal distribution\n",
    "        # The first 3 components of mu correspond to the pose of the robot,\n",
    "        # and the landmark poses (xi, yi) are stacked in ascending id order.\n",
    "        # sigma: (2N+3)x(2N+3) covariance matrix of the normal distribution\n",
    "        init_inf_val = self.init_inf_val\n",
    "        mu_arr = np.zeros((1, 2*N+3))\n",
    "        sigma_vec = np.concatenate((np.array(self.sigma_x_y_theta) ** 2, 2*N*[init_inf_val]))\n",
    "        sigma_prev = np.diag(sigma_vec)\n",
    "\n",
    "        # sigma for analysis graph sigma_x_y_t + select 2 landmarks\n",
    "        landmark1_ind = 3 #TODO\n",
    "        landmark2_ind = 13 #TODO\n",
    "\n",
    "        Index=[0,1,2,landmark1_ind,landmark1_ind+1,landmark2_ind,landmark2_ind+1]\n",
    "        sigma_x_y_t_px1_py1_px2_py2 = sigma_prev[Index,Index].copy()\n",
    "\n",
    "        observed_landmarks = np.zeros(N, dtype=bool)\n",
    "\n",
    "        sensor_data_count = int(len(sensor_data_noised) / 2)\n",
    "        frames = []\n",
    "\n",
    "        mu_arr_gt = np.array([[0, 0, 0]])\n",
    "\n",
    "        for idx in range(sensor_data_count):\n",
    "            mu_prev = mu_arr[-1].reshape(-1, 1)\n",
    "\n",
    "            u = sensor_data_noised[(idx, \"odometry\")]\n",
    "            # predict\n",
    "            mu_pred, sigma_pred = self.predict(mu_prev, sigma_prev, u, N)\n",
    "            # update (correct)\n",
    "            mu, sigma, observed_landmarks = self.update(mu_pred, sigma_pred, sensor_data_noised[(idx, \"sensor\")], observed_landmarks, N)\n",
    "\n",
    "            mu_arr = np.vstack((mu_arr, mu.T))\n",
    "            sigma_prev = sigma.copy()\n",
    "            sigma_x_y_t_px1_py1_px2_py2 = np.vstack((sigma_x_y_t_px1_py1_px2_py2, sigma_prev[Index,Index].copy()))\n",
    "\n",
    "            delta_r1_gt = sensor_data_gt[(idx, \"odometry\")][\"r1\"]\n",
    "            delta_r2_gt = sensor_data_gt[(idx, \"odometry\")][\"r2\"]\n",
    "            delta_trans_gt = sensor_data_gt[(idx, \"odometry\")][\"t\"]\n",
    "\n",
    "            calc_x = lambda theta_p: delta_trans_gt * cos(theta_p + delta_r1_gt)\n",
    "            calc_y = lambda theta_p: delta_trans_gt * sin(theta_p + delta_r1_gt)\n",
    "\n",
    "            theta = delta_r1_gt + delta_r2_gt\n",
    "\n",
    "            theta_prev = mu_arr_gt[-1,2]\n",
    "            mu_arr_gt = np.vstack((mu_arr_gt, mu_arr_gt[-1] + np.array([calc_x(theta_prev), calc_y(theta_prev), theta])))\n",
    "\n",
    "            if ax is not None:\n",
    "                frame = plot_state(ax, mu_arr_gt, mu_arr, sigma, landmarks, observed_landmarks, sensor_data_noised[(idx, \"sensor\")])\n",
    "                frames.append(frame)\n",
    "\n",
    "        return frames, mu_arr, mu_arr_gt, sigma_x_y_t_px1_py1_px2_py2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the #TODO sections within the ProjectQuestion class.\n",
    "class ProjectQuestion:\n",
    "    def __init__(self, dataset,save_results,save_animation):\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.save_results=save_results\n",
    "        self.save_animation=save_animation\n",
    "        self.fig_dir_path = os.getcwd() + \"/Results_EKFSLAM/\"\n",
    "        if not os.path.exists(self.fig_dir_path):\n",
    "            os.makedirs(self.fig_dir_path)\n",
    "\n",
    "\n",
    "    def get_odometry(self, sensor_data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sensor_data: map from a tuple (frame number, type) where type is either ‘odometry’ or ‘sensor’.\n",
    "            Odometry data is given as a map containing values for ‘r1’, ‘t’ and ‘r2’ – the first angle, the translation and the second angle in the odometry model respectively.\n",
    "            Sensor data is given as a map containing:\n",
    "              - ‘id’ – a list of landmark ids (starting at 1, like in the landmarks structure)\n",
    "              - ‘range’ – list of ranges, in order corresponding to the ids\n",
    "              - ‘bearing’ - list of bearing angles in radians, in order corresponding to the ids\n",
    "\n",
    "        Returns:\n",
    "            numpy array of dim [num of frames X 3]\n",
    "            first two components in each row are the x and y in meters\n",
    "            the third component is the heading in radians\n",
    "        \"\"\"\n",
    "        num_frames = len(sensor_data) // 2\n",
    "        state = np.array([[0, 0, 0]], dtype=float).reshape(1, 3)\n",
    "        for i in range(num_frames):\n",
    "            curr_odometry = sensor_data[i, 'odometry']\n",
    "            t = np.array([\n",
    "                curr_odometry['t'] * np.cos(state[-1, 2] + curr_odometry['r1']),\n",
    "                curr_odometry['t'] * np.sin(state[-1, 2] + curr_odometry['r1']),\n",
    "                curr_odometry['r1'] + curr_odometry['r2']\n",
    "            ]).reshape(3, 1)\n",
    "            new_pos = state[-1, :].reshape(3, 1) + t\n",
    "            state = np.concatenate([state, new_pos.reshape(1, 3)], axis=0)\n",
    "        return state\n",
    "\n",
    "    def calc_trajectory_from_odometry(self, sensor_data):\n",
    "        num_of_frames = int(len(sensor_data) / 2) # half of the list is odometry and half are sensors\n",
    "\n",
    "        # initialize the pose of the robot\n",
    "        poses = [np.array([0, 0, 0])]\n",
    "\n",
    "        # iterate over frames\n",
    "        for idx in range(num_of_frames):\n",
    "            delta_r1 = sensor_data[(idx, \"odometry\")][\"r1\"]\n",
    "            delta_r2 = sensor_data[(idx, \"odometry\")][\"r2\"]\n",
    "            delta_t = sensor_data[(idx, \"odometry\")][\"t\"]\n",
    "\n",
    "            prev_pose = poses[-1]\n",
    "            curr_pose = [prev_pose[0] + delta_t * cos(prev_pose[2] + delta_r1),\n",
    "                         prev_pose[1] + delta_t * sin(prev_pose[2] + delta_r1),\n",
    "                         prev_pose[2] + delta_r1 + delta_r2]\n",
    "\n",
    "            poses.append(curr_pose)\n",
    "\n",
    "        return np.array(poses)\n",
    "\n",
    "    def Q1(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Runs the code for question 3 of the project\n",
    "        Loads the odometry (robot motion) and sensor (landmarks) data supplied with the exercise\n",
    "        Adds noise to the odometry data r1, trans and r2\n",
    "        Uses the extended Kalman filter SLAM algorithm with the noisy odometry data to predict the path of the robot and\n",
    "        the landmarks positions\n",
    "        \"\"\"\n",
    "\n",
    "        ### a. load the data ###\n",
    "        print(\"Start EKF-SLAM.., please wait...\")\n",
    "        # Pre-processing\n",
    "        landmarks = self.dataset.load_landmarks()\n",
    "        sensor_data_gt = self.dataset.load_sensor_data()\n",
    "        N = len(landmarks)\n",
    "\n",
    "        variance_r1_t_r2 = [0.01 ** 2, 0.1 ** 2, 0.01 ** 2] #TODO  (hint- this is varinace not std..)\n",
    "        sigma_x_y_theta = [np.sqrt(variance_r1_t_r2[1]), np.sqrt(variance_r1_t_r2[1]), np.sqrt(variance_r1_t_r2[0]+variance_r1_t_r2[2])]\n",
    "        Q_additional = np.diag([0, 0, 0]) # Adding an additional system noise matrix\n",
    "        \n",
    "        #hint 1: use variance_r1_t_r2[1] and variance_r1_t_r2[0]+variance_r1_t_r2[2] ,\n",
    "        #hint 2: use std not variance) ) [np.sqrt(variance_r1_t_r2[1]), np.sqrt(variance_r1_t_r2[1]), np.sqrt(variance_r1_t_r2[0]+variance_r1_t_r2[2])]\n",
    "\n",
    "        variance_r_phi = [0.3 ** 2, 0.2 ** 2] #TODO (hint- this is varinace not std..)\n",
    "\n",
    "        ### b - c. add noise to the sensor data and plot it vs the GT ###\n",
    "\n",
    "        # add some noise to the data\n",
    "        sensor_data_noised = add_gaussian_noise_dict(sensor_data_gt, list(np.sqrt(np.array(variance_r1_t_r2))))\n",
    "\n",
    "        # calculate trajectories\n",
    "        pos_xy_gt = self.calc_trajectory_from_odometry(sensor_data_gt)\n",
    "        pos_xy_noise = self.calc_trajectory_from_odometry(sensor_data_noised)\n",
    "\n",
    "        # plot trajectory\n",
    "        graphs_slam.plot_trajectory(pos_xy_gt, 'GT trajectory from odometry', 'x [m]', 'y [m]')\n",
    "        save_graphs(self.fig_dir_path,\"GT trajectory from odometry\")\n",
    "\n",
    "        # plot trajectory + noise\n",
    "        graphs_slam.plot_trajectory_with_noise(pos_xy_gt, pos_xy_noise, 'GT vs noisy trajectory from odometry', 'x [m]', 'y [m]')\n",
    "        save_graphs(self.fig_dir_path,\"GT vs noisy trajectory from odometry\")\n",
    "        fig_anim = plt.figure()\n",
    "        ax = fig_anim.add_subplot(111)\n",
    "          # Add grid\n",
    "        ax.grid(True)\n",
    "\n",
    "        # Set title\n",
    "        ax.set_title(\"Extended Kalman Filter SLAM\")\n",
    "\n",
    "        # Set axis labels\n",
    "        ax.set_xlabel(\"X\")\n",
    "        ax.set_ylabel(\"Y\")\n",
    "        \n",
    "        ### Improving parameters and finding K\n",
    "\n",
    "        k_vector = np.arange(1, 41, 1)\n",
    "        Rmse_vec = []\n",
    "        maxE_vec = []\n",
    "        percentages_x = []\n",
    "        percentages_y = []\n",
    "        percentages_yaw = []\n",
    "\n",
    "        # Define your boundaries\n",
    "\n",
    "        for k in k_vector:\n",
    "            ekf_slam = ExtendedKalmanFilterSLAM(sigma_x_y_theta, variance_r1_t_r2, variance_r_phi, k=k)\n",
    "\n",
    "            # Run SLAM\n",
    "            _, mu_arr, mu_arr_gt, sigma_x_y_t_px1_py1_px2_py2 = ekf_slam.run(sensor_data_gt, sensor_data_noised, landmarks, ax=None)  # ax=None -> no plots\n",
    "\n",
    "            cov_x = np.sqrt(sigma_x_y_t_px1_py1_px2_py2[:,0])\n",
    "            cov_y = np.sqrt(sigma_x_y_t_px1_py1_px2_py2[:,1])\n",
    "            cov_yaw = np.sqrt(sigma_x_y_t_px1_py1_px2_py2[:,2])\n",
    "            \n",
    "            # Compute RMSE and max error\n",
    "            RMSE, maxE, X_Y_diff = ExtendedKalmanFilterSLAM.calc_RMSE_maxE(mu_arr, mu_arr_gt)\n",
    "\n",
    "            # Compute error vectors\n",
    "            x_errors = mu_arr_gt[:, 0] - mu_arr[:, 0]\n",
    "            y_errors = mu_arr_gt[:, 1] - mu_arr[:, 1]\n",
    "            yaw_errors = np.vectorize(normalize_angle)(mu_arr_gt[:, 2] - mu_arr[:, 2])\n",
    "\n",
    "            # Compute error percentages\n",
    "            percentage_x = percentage_within_boundary(x_errors, cov_x)\n",
    "            percentage_y = percentage_within_boundary(y_errors, cov_y)\n",
    "            percentage_yaw = percentage_within_boundary(yaw_errors, cov_yaw)\n",
    "\n",
    "            # Store results\n",
    "            Rmse_vec.append(RMSE)\n",
    "            maxE_vec.append(maxE)\n",
    "            percentages_x.append(percentage_x)\n",
    "            percentages_y.append(percentage_y)\n",
    "            percentages_yaw.append(percentage_yaw)\n",
    "\n",
    "        # Create a DataFrame\n",
    "        results_df = pd.DataFrame({\n",
    "        'k': k_vector,\n",
    "        'RMSE [m]': Rmse_vec,\n",
    "        'maxE [m]': maxE_vec,\n",
    "        'Percentage X within boundary [%]': percentages_x,\n",
    "        'Percentage Y within boundary [%]': percentages_y,\n",
    "        'Percentage YAW within boundary [%]': percentages_yaw})\n",
    "\n",
    "        # Optionally, save the results to a CSV file\n",
    "        if self.save_results:\n",
    "            results_df.to_csv(f\"{self.fig_dir_path}/error_analysis.csv\", index=False)\n",
    "            print(\"Saving error analysis\")\n",
    "\n",
    "        ### d - h. ExtendedKalmanFilterSLAM ###\n",
    "        \n",
    "        k_vector = np.arange(1, 10.10, 0.10)\n",
    "        Rmse_vec = []; maxE_vec = []\n",
    "        for k in k_vector:\n",
    "            ekf_slam = ExtendedKalmanFilterSLAM(sigma_x_y_theta, variance_r1_t_r2, variance_r_phi, k=k)\n",
    "\n",
    "            # frames, mu_arr, mu_arr_gt, sigma_x_y_t_px1_py1_px2_py2 = ekf_slam.run(sensor_data_gt, sensor_data_noised, landmarks, ax=None) # ax = None -> no plots\n",
    "            _, mu_arr, mu_arr_gt, _ = ekf_slam.run(sensor_data_gt, sensor_data_noised, landmarks, ax=None) # ax = None -> no plots\n",
    "\n",
    "            RMSE, maxE ,X_Y_diff = ExtendedKalmanFilterSLAM.calc_RMSE_maxE(mu_arr, mu_arr_gt)\n",
    "\n",
    "            Rmse_vec.append(RMSE)\n",
    "            maxE_vec.append(maxE)\n",
    "\n",
    "        min_idx_rmse = np.argmin(Rmse_vec)\n",
    "        min_idx_maxE = np.argmin(maxE_vec)\n",
    "\n",
    "        fig_calib, axes_calib = plt.subplots(2,1)\n",
    "        axes_calib[0].plot(k_vector, Rmse_vec)\n",
    "        axes_calib[0].scatter(k_vector[min_idx_rmse], Rmse_vec[min_idx_rmse])\n",
    "        axes_calib[0].set_title('RMSE vs sigma_theta values \\n min for k = '+str(round(k_vector[min_idx_rmse], 3)))\n",
    "        axes_calib[0].set(xlabel='sigma_theta', ylabel='Rmse')\n",
    "        axes_calib[0].grid()\n",
    "        axes_calib[1].plot(k_vector, maxE_vec)\n",
    "        axes_calib[1].scatter(k_vector[min_idx_maxE], maxE_vec[min_idx_maxE])\n",
    "        axes_calib[1].set_title('maxE vs sigma_n values \\n min for k = '+str(round(k_vector[min_idx_maxE],3)))\n",
    "        axes_calib[1].set(xlabel='sigma_theta', ylabel='maxE')\n",
    "        axes_calib[1].grid()\n",
    "        fig_calib.tight_layout()\n",
    "\n",
    "        save_graphs(self.fig_dir_path,\"Extended Kalman filter SLAM calibration\")\n",
    "\n",
    "        opt_k = k_vector[min_idx_rmse]\n",
    "        \n",
    "        ekf_slam = ExtendedKalmanFilterSLAM(sigma_x_y_theta, variance_r1_t_r2, variance_r_phi, k=opt_k)\n",
    "        frames, mu_arr, mu_arr_gt, sigma_x_y_t_px1_py1_px2_py2 = ekf_slam.run(sensor_data_gt, sensor_data_noised, landmarks, ax)\n",
    "        RMSE, maxE,X_Y_diff = ExtendedKalmanFilterSLAM.calc_RMSE_maxE(mu_arr, mu_arr_gt)\n",
    "        print(\"EKF-SLAM: RMSE = \" + str(round(RMSE, 3))+\" [m], maxE = \"+str(round(maxE,3))+\" [m]\")\n",
    "\n",
    "        # save the analysis figures\n",
    "        if self.save_results:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "            fig.suptitle(\"Extended Kalman Filter SLAM Trajectory Results \\n k = \" + str(opt_k) + \"\\nRMSE = \" + str(round(RMSE, 3)) + \", maxE = \"+str(round(maxE,3)))\n",
    "            ax.plot(mu_arr_gt[:,0], mu_arr_gt[:,1], label='GT')\n",
    "            ax.plot(mu_arr[:,0], mu_arr[:,1], label='EKF-SLAM')\n",
    "            ax.set(xlabel='x[m]', ylabel='y[m]')\n",
    "            ax.grid()\n",
    "            ax.legend()\n",
    "\n",
    "            save_graphs(self.fig_dir_path,\"Extended Kalman SLAM filter results vs GT\")\n",
    "            angle_error = np.vectorize(normalize_angle)(mu_arr_gt[:,2] - mu_arr[:,2])\n",
    "            plot_error([mu_arr_gt[:,0] - mu_arr[:,0],np.sqrt(sigma_x_y_t_px1_py1_px2_py2[:,0])],[mu_arr_gt[:,1] - mu_arr[:,1],np.sqrt(sigma_x_y_t_px1_py1_px2_py2[:,1])],[angle_error,np.sqrt(sigma_x_y_t_px1_py1_px2_py2[:,2])])\n",
    "            save_graphs(self.fig_dir_path,\"state_vector_Error- GT - EKFSLAM\")\n",
    "\n",
    "            Lk1x=[np.tile(landmarks[1][0], mu_arr.shape[0]) - mu_arr[:,3],np.sqrt(sigma_x_y_t_px1_py1_px2_py2[:,3])]\n",
    "            Lk1y=[np.tile(landmarks[1][1], mu_arr.shape[0]) - mu_arr[:,4],np.sqrt(sigma_x_y_t_px1_py1_px2_py2[:,4])]\n",
    "            plot_error(Lk1x,Lk1y)\n",
    "            save_graphs(self.fig_dir_path,\"landmark1_Error- GT - EKFSLAM\")\n",
    "\n",
    "            Lk2x=[np.tile(landmarks[2][0], mu_arr.shape[0]) - mu_arr[:,5],np.sqrt(sigma_x_y_t_px1_py1_px2_py2[:,5])]\n",
    "            Lk2y=[np.tile(landmarks[2][1], mu_arr.shape[0]) - mu_arr[:,6],np.sqrt(sigma_x_y_t_px1_py1_px2_py2[:,6])]\n",
    "            plot_error(Lk2x,Lk2y)\n",
    "            save_graphs(self.fig_dir_path,\"landmark2_Error- GT - EKFSLAM\")\n",
    "\n",
    "\n",
    "\n",
    "        ax.set_xlim([-2, 12])\n",
    "        ax.set_ylim([-2, 12])\n",
    "         # save the animation\n",
    "        if self.save_animation:\n",
    "            print(\"Saving animation..wait...\")\n",
    "            ani = animation.ArtistAnimation(fig_anim, frames, repeat=False)\n",
    "            ani.save(self.fig_dir_path +'Extended Kalman Filter SLAM.mp4', metadata={'artist':'me'})\n",
    "            graphs_slam.show_graphs()\n",
    "            print(\"Done!...\")\n",
    "\n",
    "    def run(self):\n",
    "        self.Q1()\n",
    "        print(\"Successfully finished. All data saved in {}\".format(self.fig_dir_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start EKF-SLAM.., please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nadav\\AppData\\Local\\Temp\\ipykernel_22208\\2684809251.py:37: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  G_x = np.eye(3) + np.array([[0, 0, -1*delta_trans*sin(theta_prev + delta_rot1)], [0, 0, delta_trans*cos(theta_prev + delta_rot1)], [0, 0, 0]])\n",
      "C:\\Users\\Nadav\\AppData\\Local\\Temp\\ipykernel_22208\\2684809251.py:39: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  V = np.array([[-1*delta_trans*sin(theta_prev+delta_rot1), cos(theta_prev+delta_rot1), 0],\n",
      "C:\\Users\\Nadav\\AppData\\Local\\Temp\\ipykernel_22208\\2684809251.py:40: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  [delta_trans*cos(theta_prev+delta_rot1), sin(theta_prev+delta_rot1), 0],\n",
      "C:\\Users\\Nadav\\AppData\\Local\\Temp\\ipykernel_22208\\2684809251.py:47: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  odometry_model_next_step=np.array([[delta_trans*cos(theta_prev + delta_rot1)], [delta_trans*sin(theta_prev + delta_rot1)],[delta_rot1 + delta_rot2]])\n",
      "C:\\Users\\Nadav\\AppData\\Local\\Temp\\ipykernel_22208\\2684809251.py:83: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  q = float((delta.T) @ delta)\n",
      "C:\\Users\\Nadav\\AppData\\Local\\Temp\\ipykernel_22208\\2684809251.py:109: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  mu[2] = normalize_angle(float(mu[2]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving error analysis\n",
      "EKF-SLAM: RMSE = 0.2 [m], maxE = 0.594 [m]\n",
      "Saving animation..wait...\n",
      "Done!...\n",
      "Successfully finished. All data saved in C:\\Users\\Nadav/Results_EKFSLAM/\n"
     ]
    }
   ],
   "source": [
    "seed = 50 #dont change seed number\n",
    "np.random.seed(seed)\n",
    "\n",
    "save_results=True\n",
    "save_animation=True\n",
    "\n",
    "project = ProjectQuestion(dataset,save_results,save_animation)\n",
    "project.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "22d54b2afd460569b9e9050ca66571082a0929281e5b28d20c6fd75528a62769"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
